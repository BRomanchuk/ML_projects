{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5068d0",
   "metadata": {},
   "source": [
    "# House Prices Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6eb14",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(22,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b83b5",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col='Id')\n",
    "test = pd.read_csv('./data/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284cd956",
   "metadata": {},
   "source": [
    "### First outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['GrLivArea'].sort_values(ascending=False).head(), test['GrLivArea'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de3148",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find outliers\n",
    "plt.scatter(train['GrLivArea'], train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6bcc1",
   "metadata": {},
   "source": [
    "#### First method - drop outliers from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter for outliers\n",
    "# area_outliers_mask = (train['GrLivArea'] > 4000)\n",
    "\n",
    "# # drop outliers from training set\n",
    "# train.drop(train.loc[area_outliers_mask].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68fa252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(train['GrLivArea'], train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5bf04",
   "metadata": {},
   "source": [
    "#### Second method - mark all outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters for train and test sets\n",
    "outlier_train_mask = (train['GrLivArea'] > 4500)\n",
    "outlier_test_mask = (test['GrLivArea'] > 4500)\n",
    "\n",
    "train['Outlier'] = np.zeros(train.shape[0])\n",
    "test['Outlier'] = np.zeros(test.shape[0])\n",
    "\n",
    "train.loc[outlier_train_mask, 'Outlier'] = 100\n",
    "test.loc[outlier_test_mask, 'Outlier'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d7f058",
   "metadata": {},
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fec21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266237c8",
   "metadata": {},
   "source": [
    "### Drop columns with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef349f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce42ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns that have more than 70% of NaNs\n",
    "for col in data.columns:\n",
    "    if data[col].isna().sum() > 0.7 * data.shape[0]:\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03107f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e486c",
   "metadata": {},
   "source": [
    "### Drop columns with different categories in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = []\n",
    "\n",
    "for col in data.drop('SalePrice', axis=1).columns:\n",
    "    if train[col].dtype not in ['float64', 'int64']:\n",
    "        if (data.loc[data[col].notnull(), col].unique() != train.loc[train[col].notnull(), col].unique()).any():\n",
    "            cols_to_drop.append(col)\n",
    "            print(col)\n",
    "\n",
    "# data.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50b165",
   "metadata": {},
   "source": [
    "### Fill NaNs \n",
    "<b>in categorical features</b><br>\n",
    "<i> - with mode</i><br>\n",
    "<i> - with \"Missing\" if the number of missing values is too high</i><br>\n",
    "<b>in numeric features</b><br>\n",
    "<i> - with median</i><br>\n",
    "<i> - with -999 if the number of missing values is too high</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns with missing values\n",
    "na_columns = data.drop('SalePrice', axis=1).columns[(data.drop('SalePrice', axis=1).isna().sum() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaNs\n",
    "for col in na_columns:\n",
    "    if data[col].isnull().sum() < 0.4 * data.shape[0]:\n",
    "        if str(data[col].dtype) == 'float64':\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "        else:\n",
    "            data[col].fillna(data[col].mode(), inplace=True)\n",
    "            data[col].replace({None: data[col].mode()[0]}, inplace=True)\n",
    "    else:\n",
    "        if str(data[col].dtype) == 'object':\n",
    "            data[col].fillna('Missing', inplace=True)\n",
    "            data[col].replace({None: 'Missing'}, inplace=True)\n",
    "        else:\n",
    "            data[col].fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40686105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the numbers of unique values of the non-integer categorical features\n",
    "values_arr = []\n",
    "for col in data.columns:\n",
    "    if data[col].dtype not in ['float64', 'int64']:\n",
    "        values_arr.append(len(data[col].unique()))\n",
    "np.array(values_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea329ea0",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c908bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age of the house\n",
    "data['HouseAge'] = data['YrSold'] - data['YearBuilt']\n",
    "\n",
    "# years since the last remodeling\n",
    "data['ModelAge'] = data['YrSold'] - data['YearRemodAdd']\n",
    "\n",
    "# is remodeled or not\n",
    "# remodeled_mask = (data['YearBuilt'] != data['YearRemodAdd'])\n",
    "# data['Remodeled'] = np.zeros(data.shape[0])\n",
    "# data.loc[remodeled_mask, 'Remodeled'] = 1\n",
    "\n",
    "# drop previous columns\n",
    "data.drop(['YearBuilt', 'YearRemodAdd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be21b32",
   "metadata": {},
   "source": [
    "### Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e70389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9175ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "for col in data.drop('SalePrice', axis=1).columns:\n",
    "    if data[col].dtype not in ['float64', 'int64']:\n",
    "        matrix = lb.fit_transform(data[col]).T\n",
    "        unique = data[col].unique()\n",
    "        # if columns is binary, LabelBinarizer returns 1d-array instead of 2d-matrix\n",
    "        if matrix.shape[0] == 1:\n",
    "            data[col] = matrix[0]\n",
    "        else:\n",
    "            for i in range(len(unique)):\n",
    "                data[str(col + unique[i])] = matrix[i]\n",
    "            # remove previous column\n",
    "            data.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1410db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c210fe",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d71688",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['SalePrice']\n",
    "data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "train = data.iloc[:train.shape[0]]\n",
    "test = data.iloc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac79d1a",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b50274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import instruments for model evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dcfd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define error function [RMSE(log(y), log(y_pred))]\n",
    "# RMSE - Root-Mean-Square Error\n",
    "def error(Y_real, Y_pred):\n",
    "    return np.sqrt(mse(np.log(Y_real), np.log(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81156a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models\n",
    "models = [\n",
    "    XGBRegressor(),\n",
    "    RandomForestRegressor()\n",
    "]\n",
    "\n",
    "# K-Fold splitter\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "# Model evaluation DataFrame\n",
    "log_df = pd.DataFrame(columns=['Model', 'Error'])\n",
    "log_dict = {}\n",
    "\n",
    "for train_ind, test_ind in kfold.split(train, y_train):\n",
    "    X_train, Y_train = train.iloc[train_ind], y_train.iloc[train_ind]\n",
    "    X_test, Y_test = train.iloc[test_ind], y_train.iloc[test_ind]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        \n",
    "        err = error(Y_test, Y_pred)\n",
    "        \n",
    "        if name in log_dict:\n",
    "            log_dict[name] += err\n",
    "        else:\n",
    "            log_dict[name] = err\n",
    "\n",
    "for model in log_dict:\n",
    "    row = {'Model': model, 'Error': log_dict[model] / 10}\n",
    "    log_df = log_df.append(row, ignore_index=True)\n",
    "\n",
    "log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c639b",
   "metadata": {},
   "source": [
    "### Prediction of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = XGBRegressor()\n",
    "best.fit(train, y_train)\n",
    "\n",
    "predictions = best.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe46009",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.columns, best.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8013e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e344b1c",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b84e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('./data/sample_submission.csv', index_col='Id')\n",
    "submission_df['SalePrice'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5aa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manually change the price of the outlier in the test set\n",
    "# outlier_mask = (test['GrLivArea'] > 5000)\n",
    "# submission_df.loc[outlier_mask, 'SalePrice'] = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c26932",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./result/XGB_with_outliers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
