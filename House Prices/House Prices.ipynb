{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5068d0",
   "metadata": {},
   "source": [
    "# House Prices Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6eb14",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(22,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b83b5",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col='Id')\n",
    "test = pd.read_csv('./data/test.csv', index_col='Id')\n",
    "\n",
    "# all data\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b32267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aece0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266237c8",
   "metadata": {},
   "source": [
    "### Drop columns with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce42ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns that have more than 70% of NaNs\n",
    "for col in data.columns:\n",
    "    if data[col].isna().sum() > 0.7 * data.shape[0]:\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03107f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa4217e",
   "metadata": {},
   "source": [
    "### Drop columns with different categories in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a950e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = []\n",
    "\n",
    "for col in data.drop('SalePrice', axis=1).columns:\n",
    "    if train[col].dtype not in ['float64', 'int64']:\n",
    "        if (data.loc[data[col].notnull(), col].unique() != train.loc[train[col].notnull(), col].unique()).any():\n",
    "            cols_to_drop.append(col)\n",
    "            print(col)\n",
    "\n",
    "# data.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50b165",
   "metadata": {},
   "source": [
    "### Fill NaNs \n",
    "<b>in categorical features</b><br>\n",
    "<i> - with mode</i><br>\n",
    "<i> - with \"Missing\" if the number of missing values is too high</i><br>\n",
    "<b>in numeric features</b><br>\n",
    "<i> - with median</i><br>\n",
    "<i> - with -999 if the number of missing values is too high</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns with missing values\n",
    "na_columns = data.drop('SalePrice', axis=1).columns[(data.drop('SalePrice', axis=1).isna().sum() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaNs\n",
    "for col in na_columns:\n",
    "    if data[col].isnull().sum() < 0.4 * data.shape[0]:\n",
    "        if str(data[col].dtype) == 'float64':\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "        else:\n",
    "            data[col].fillna(data[col].mode(), inplace=True)\n",
    "            data[col].replace({None: data[col].mode()[0]}, inplace=True)\n",
    "    else:\n",
    "        if str(data[col].dtype) == 'object':\n",
    "            data[col].fillna('Missing', inplace=True)\n",
    "            data[col].replace({None: 'Missing'}, inplace=True)\n",
    "        else:\n",
    "            data[col].fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40686105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the numbers of unique values of the non-integer categorical features\n",
    "values_arr = []\n",
    "for col in data.columns:\n",
    "    if data[col].dtype not in ['float64', 'int64']:\n",
    "        values_arr.append(len(data[col].unique()))\n",
    "np.array(values_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfec9e8",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age of the house\n",
    "data['HouseAge'] = 2021 - data['YearBuilt']\n",
    "\n",
    "# years since the last remodeling\n",
    "data['ModelAge'] = 2021 - data['YearRemodAdd']\n",
    "\n",
    "# is remodeled or not\n",
    "# remodeled_mask = (data['YearBuilt'] != data['YearRemodAdd'])\n",
    "# data['Remodeled'] = np.zeros(data.shape[0])\n",
    "# data.loc[remodeled_mask, 'Remodeled'] = 1\n",
    "\n",
    "# drop previous columns\n",
    "data.drop(['YearBuilt', 'YearRemodAdd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5e323",
   "metadata": {},
   "source": [
    "### Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "for col in data.drop('SalePrice', axis=1).columns:\n",
    "    if data[col].dtype not in ['float64', 'int64']:\n",
    "        matrix = lb.fit_transform(data[col]).T\n",
    "        unique = data[col].unique()\n",
    "        # if columns is binary, LabelBinarizer returns 1d-array instead of 2d-matrix\n",
    "        if matrix.shape[0] == 1:\n",
    "            data[col] = matrix[0]\n",
    "        else:\n",
    "            for i in range(len(unique)):\n",
    "                data[unique[i]] = matrix[i]\n",
    "            # remove previous column\n",
    "            data.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a60701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if len(data[col].unique()) == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb133f",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['SalePrice']\n",
    "data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "train = data.iloc[:train.shape[0]]\n",
    "test = data.iloc[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e5780",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0896caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import instruments for model evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define error function [RMSE(log(y), log(y_pred))]\n",
    "def error(Y_real, Y_pred):\n",
    "    return np.sqrt(mse(np.log(Y_real), np.log(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models\n",
    "models = [\n",
    "    XGBRegressor(),\n",
    "    RandomForestRegressor()\n",
    "]\n",
    "\n",
    "# K-Fold splitter\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "# Model evaluation DataFrame\n",
    "log_df = pd.DataFrame(columns=['Model', 'Error'])\n",
    "log_dict = {}\n",
    "\n",
    "for train_ind, test_ind in kfold.split(train, y_train):\n",
    "    X_train, Y_train = train.iloc[train_ind], y_train.iloc[train_ind]\n",
    "    X_test, Y_test = train.iloc[test_ind], y_train.iloc[test_ind]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        \n",
    "        err = error(Y_test, Y_pred)\n",
    "        \n",
    "        if name in log_dict:\n",
    "            log_dict[name] += err\n",
    "        else:\n",
    "            log_dict[name] = err\n",
    "\n",
    "for model in log_dict:\n",
    "    row = {'Model': model, 'Error': log_dict[model] / 10}\n",
    "    log_df = log_df.append(row, ignore_index=True)\n",
    "\n",
    "log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47010f0f",
   "metadata": {},
   "source": [
    "### Prediction with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ecf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = XGBRegressor()\n",
    "best.fit(train, y_train)\n",
    "\n",
    "predictions = best.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f524f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('./data/sample_submission.csv', index_col='Id')\n",
    "submission_df['SalePrice'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f205a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./result/XGB.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
